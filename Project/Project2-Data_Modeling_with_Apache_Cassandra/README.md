### **Project Overview**
This project is built to create Apache Cassandra tables to run queries on song play analysis for new music streaming app of Sparkify. 

### **Data**

* **Event Dataset**
  
  Each file is in CSV format generated by event simulator.
  The directory of CSV files partitioned by date. Examples of filepaths to two files in the dataset:

      event_data/2018-11-08-events.csv
      event_data/2018-11-09-events.csv

### **Project Steps**

#### **Modeling Apache Cassandra database**
1. Design tables to answer given queries
2. Write Apache Cassandra `CREATE KEYSPACE` and `SET KEYSPACE` statements
3. Develop `CREATE` statement for each of the tables to address each question
4. Load the data with `INSERT` statement for each of the tables
5. Include `IF NOT EXISTS` clauses in `CREATE` statements to create tables only if the tables do not already exist. Also, include `DROP TABLE` statement for each table, this way I can drop and create tables whenever I want to reset database and test ETL pipeline
6. Test by running the proper select statements with the correct `WHERE` clause

#### **Build ETL Pipeline**
1. Iterate through each event file in `event_data` to process and create a new CSV file in Python 
2. Include Apache Cassandra `CREATE` and `INSERT` statements to load processed records into relevant tables in data model
3. Test by running `SELECT` statements after running the queries on the database
