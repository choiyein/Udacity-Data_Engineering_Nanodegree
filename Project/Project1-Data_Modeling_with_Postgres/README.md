# **Data Modeling with Postgres**
This project is built to create a Postgres database with tables designed to optimize queries on song play analysis for new music streaming app of Sparkify. 

## **Data**
Sparkify has been collecting data regarding songs and user activity on the app.
* **Song Dataset**

    Each file is in JSON format and contains metadata about a song and the artist of that song.

        {"num_songs": 1, "artist_id": "ARBGXIG122988F409D", "artist_latitude": 37.77916, "artist_longitude": -122.42005, "artist_location": "California - SF", "artist_name": "Steel Rain", "song_id": "SOOJPRH12A8C141995", "title": "Loaded Like A Gun", "duration": 173.19138, "year": 0}

* **Log Dataset**
    
    Log dataset consists of log files in JSON format generated by [event simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. The log files in the dataset are partitioned by year and month.

    A log in a log file looks like: 
     
        {"artist":null,"auth":"Logged In","firstName":"Walter","gender":"M","itemInSession":0,"lastName":"Frye","length":null, "level":"free","location":"San Francisco-Oakland-Hayward, CA","method":"GET","page":"Home","registration":1540919166796.0, "sessionId":38,"song":null,"status":200,"ts":1541105830796,"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"","userId":"39"} 


## **Database Schema**
Here, Star schema is utilized to speed up read queries by culling out data releated to business and separating it from descriptive data.

* **Fact Table**
    * **songplays** 

        Records in log data associated with song plays

        |       Column        |       Type         |     Description    |
        |:-------------------:|:------------------:|:------------------:|
        | `songplay_id` | SERIAL, PRIMARY KEY | Unique identifier of song plays|
        | `start_time`  | TIMESTAMP, NOT NULL, FOREIGN KEY | Time when song plays happened |
        | `user_id`     | INT, NOT NULL, FOREIGN KEY | Unique identifier of  users |  
        | `level`       | VARCHAR | Level of users: paid or free plan | 
        | `song_id`     | VARCHAR, FOREIGN KEY | Unique identifier of songs | 
        | `artist_id`   | VARCHAR, FOREIGN KEY | Unique identifier of artists |
        | `session_id`  | INT | Unique identifier of sessions | 
        | `location`    | VARCHAR | Location of users | 
        | `user_agent`  | VARCHAR | Agent used to access Sparkify music app |

* **Dimension Tables**
    * **users**

        Users in the app
        |       Column        |       Type         |     Description    |
        |:-------------------:|:------------------:|:------------------:|
        | `user_id` | INT, PRIMARY KEY | Unique identifier of users |
        | `first_name` | VARCHAR | first name of the user |
        | `last_name` | VARCHAR | last name of the user |
        | `gender` | CHAR(1) | gender of the user: F or M |
        | `level` | VARCHAR | Level of the user: paid or free plan |  

    * **songs**

        Songs in the music database

        |       Column        |       Type         |     Description    |
        |:-------------------:|:------------------:|:------------------:|
        | `song_id` | VARCHAR, PRIMARY KEY | Unique identifier of songs |  
        | `title` | VARCHAR | Name of the song | 
        | `artist_id` | VARCHAR, NOT NULL, FOREIGN KEY | Artist id of the song | 
        | `year` | INT | Year when the song was realeased |
        | `duration` | NUMERIC | Duration of the song in ms | 

    * **artists**

        Artists in the music database

        |       Column        |       Type         |     Description    |
        |:-------------------:|:------------------:|:------------------:|
        | `artist_id` | VARCHAR, PRIMARY KEY | Unique identifier of artists | 
        | `name` | VARCHAR | Name of the artist |
        | `location` | VARCHAR | Location of the artist |
        | `latitude` | NUMERIC | Latitude of the location of the artist | 
        | `longitude` | NUMERIC | Longitude of the location of the artist |  

    * **time**

        Timestamps of records in songplays broken down into specific units

        |       Column        |       Type         |     Description    |
        |:-------------------:|:------------------:|:------------------:|        
        | `start_time` | TIMESTAMP, PRIMARY KEY | Time when song plays happened |
        | `hour` | INT, NOT NULL | Hour of the `start_time` | 
        | `day` | INT, NOT NULL | Day of the `start_time` |
        | `week` | INT, NOT NULL | Week of year for `start_time` | 
        | `month` | INT, NOT NULL | Month of `start_time` |
        | `year` | INT, NOT NULL | Year of `start_time` | 
        | `weekday` | INT, NOT NULL | Day of the week of `start_time`: Monday=0, Sunday=6 | 

## **ETL Pipeline**
* **Extract** 

    1. Define a function to get all files matching extension from directory
    
            def get_files(filepath):
                all_files = []
                for root, dirs, files in os.walk(filepath):
                    files = glob.glob(os.path.join(root,'*.json'))
                    for f in files :
                        all_files.append(os.path.abspath(f))
                return all_files

   2. Data is extracted from JSON files using json and pandas library in Python. 

* **Transform**

    * **songs** & **artists** & **users**
    
       1. Select columns that each table needs 
       2. Take just the values from dataframe
       3. Convert the array to a list and set aside the list

    * **time**:

        1. Filter records whose the value of `page` column equals `NextSong`
        2. Convert type of `start_time` (`ts`) column to datetime
        3. Extract the timestamp, hour, day, week of year, month, year, and weekday from the `start_time` (`ts`) column and set those to a tuple containing these values in order
        4. Create a dataframe, time_df, containing the time data by combining column_labels and time_data into a dictionary and converting this into a dataframe

    * **songplays**

        1. Implement the song_select query in sql_queries.py to find the song ID and artist ID based on the title, artist name, and duration of a song.
        2. Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to a tuple named songplay_data

* **Load**

    1. Create and connect to the sparkifydb using psycopg2 library in Python
    2. Create all tables needed
    3. Insert transformed data into tables in the database named sparkifydb 

### **How to run the scripts**

   1. Run **create_tables.py** in the console: 
        
            python create_tables.py
        
   2. Then, run **etl.py** in the console:

            python etl.py